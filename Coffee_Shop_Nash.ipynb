{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game theory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from random import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coffee_Strategy:\n",
    "    actions = ['bakery', 'bagels', 'diner','icecream_and_froyo','purely_coffee','coffee_and_tea']\n",
    "    n_actions = 6\n",
    "    ##below complete reading in pandas dataframe\n",
    "    utilities = pd.DataFrame([],\n",
    "\n",
    "    columns=actions, index=actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name):\n",
    "        self.strategy, self.avg_strategy,\\\n",
    "        self.strategy_sum, self.regret_sum = np.zeros((4, Coffee_Strategy.n_actions))\n",
    "        self.name = name\n",
    "    def __repr__(self):\n",
    "        return self.name \n",
    "    def update_strategy(self):\n",
    "        \"\"\"\n",
    "        set the strategy of choosing a category of coffee shop  to be proportional to positive regrets\n",
    "        \"\"\"\n",
    "        self.strategy = np.copy(self.regret_sum)\n",
    "        self.strategy[self.strategy < 0] = 0  # reset negative regrets to zero\n",
    "\n",
    "        summation = sum(self.strategy)\n",
    "        if summation > 0:\n",
    "            # normalise\n",
    "            self.strategy /= summation\n",
    "        else:\n",
    "            # uniform distribution to reduce exploitability\n",
    "            self.strategy = np.repeat(1 / Coffee_Strategy.n_actions, Coffee_Strategy.n_actions)\n",
    "\n",
    "        self.strategy_sum += self.strategy\n",
    "    def regret(self, my_action, opp_action):\n",
    "        \"\"\"\n",
    "        define the regret of not having chosen an action as the difference between the utility of that action\n",
    "        and the utility of the action we actually chose, with respect to the fixed choices of the other player.\n",
    "        compute the regret and add it to regret sum.\n",
    "        \"\"\"\n",
    "        result = Coffee_Strategy.utilities.loc[my_action, opp_action]\n",
    "        facts = Coffee_Strategy.utilities.loc[:, opp_action].values\n",
    "        regret = facts - result\n",
    "        self.regret_sum += regret\n",
    "\n",
    "    def action(self, use_avg=False):\n",
    "        \"\"\"\n",
    "        select an action according to coffee category probabilities\n",
    "        \"\"\"\n",
    "        strategy = self.avg_strategy if use_avg else self.strategy\n",
    "        return np.random.choice(Coffee_Strategy.actions, p=strategy)\n",
    "\n",
    "    def learn_avg_strategy(self):\n",
    "        # averaged strategy converges to Nash Equilibrium\n",
    "        summation = sum(self.strategy_sum)\n",
    "        if summation > 0:\n",
    "            self.avg_strategy = self.strategy_sum / summation\n",
    "        else:\n",
    "            self.avg_strategy = np.repeat(1/Coffee_Strategy.n_actions, Coffee_Strategy.n_actions)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete below class to finish game and evaluate Nash eq for each pair of target coffeeshop and neighbor.To complete...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, max_game=10000):\n",
    "        self.p1 = Player('Target Coffee Shop')\n",
    "        self.p2 = Player('Neighbor Coffee Shop')\n",
    "        self.max_game = max_game\n",
    "\n",
    "    def winner(self, a1, a2):\n",
    "        result = Coffee_Strategy.utilities.loc[a1, a2]\n",
    "        if result == 1:     return self.p1\n",
    "        elif result == -1:  return self.p2\n",
    "        else:               return 'Draw'\n",
    "\n",
    "    def play(self, avg_regret_matching=False):\n",
    "        def play_regret_matching():\n",
    "            for i in xrange(0, self.max_game):\n",
    "                self.p1.update_strategy()\n",
    "                self.p2.update_strategy()\n",
    "                a1 = self.p1.action()\n",
    "                a2 = self.p2.action()\n",
    "                self.p1.regret(a1, a2)\n",
    "                self.p2.regret(a2, a1)\n",
    "\n",
    "                winner = self.winner(a1, a2)\n",
    "                num_wins[winner] += 1\n",
    "\n",
    "        def play_avg_regret_matching():\n",
    "            for i in xrange(0, self.max_game):\n",
    "                a1 = self.p1.action(use_avg=True)\n",
    "                a2 = self.p2.action(use_avg=True)\n",
    "                winner = self.winner(a1, a2)\n",
    "                num_wins[winner] += 1\n",
    "\n",
    "        num_wins = {\n",
    "            self.p1: 0,\n",
    "            self.p2: 0,\n",
    "            'Draw': 0\n",
    "        }\n",
    "\n",
    "        play_regret_matching() if not avg_regret_matching else play_avg_regret_matching()\n",
    "        print num_wins\n",
    "\n",
    "    def conclude(self):\n",
    "        \"\"\"\n",
    "         conclude the average strategy from the previous strategy stats until Nash eq.\n",
    "        \"\"\"\n",
    "        self.p1.learn_avg_strategy()\n",
    "        self.p2.learn_avg_strategy()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    game = Game()\n",
    "\n",
    "    print '==== Use simple regret-matching strategy === '\n",
    "    game.play()\n",
    "    print '==== Nash eq === '\n",
    "    game.conclude()\n",
    "game.play(avg_regret_matching=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
